{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Prediction of Obesity Risk\n",
    "\n",
    "**Programa de Engenharia de Sistemas e Computação**\n",
    "\n",
    "**CPS833 - Data Mining**\n",
    "\n",
    "**Professor**: Geraldo Zimbrão da Silva\n",
    "\n",
    "**Aluno**: Luiz Henrique Souza Caldas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.target import FeatureCorrelation\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_overview(tr_d, te_d):\n",
    "    # Identifica duplicatas no conjunto de dados de treinamento\n",
    "    tr_duplicates = tr_d.duplicated().sum()\n",
    "    # Identifica duplicatas no conjunto de dados de teste\n",
    "    te_duplicates = te_d.duplicated().sum()\n",
    "\n",
    "    # Impressão dos resultados\n",
    "    print(f\"Number of duplicate rows in training data: {tr_duplicates}\")\n",
    "    print(f\"Number of duplicate rows in test data: {te_duplicates}\")\n",
    "\n",
    "    # Se existirem duplicatas, exibe mais detalhes\n",
    "    if tr_duplicates > 0:\n",
    "        print(\"Duplicate rows in training data:\")\n",
    "        display(tr_d[tr_d.duplicated(keep=False)])  # Mostra todas as linhas duplicadas\n",
    "\n",
    "    if te_duplicates > 0:\n",
    "        print(\"Duplicate rows in test data:\")\n",
    "        display(te_d[te_d.duplicated(keep=False)])  # Mostra todas as linhas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dados faltantes\n",
      "0 linhas duplicadas\n",
      "Number of duplicate rows in training data: 0\n",
      "Number of duplicate rows in test data: 0\n"
     ]
    }
   ],
   "source": [
    "# Importação dos dados\n",
    "train_dataset = pd.read_csv('train.csv')\n",
    "\n",
    "# Verificação de dados ausentes (limpeza de dados)\n",
    "print(f\"{train_dataset.isnull().any().sum()} dados faltantes\")\n",
    "\n",
    "# Verificação de linhas duplicadas (redução de dimensionalidade)\n",
    "print(f\"{train_dataset.duplicated().sum()} linhas duplicadas\")\n",
    "data_overview(train_dataset,train_dataset)\n",
    "\n",
    "# TODO Verificação de ouliers (redução de dimensionalidade)\n",
    "\n",
    "\n",
    "# Codificando features categóricas com Label Encoder (transformação de dados)\n",
    "label_encoder = LabelEncoder()\n",
    "train_dataset_encoded = train_dataset.copy()  # Faz uma cópia do dataset para evitar alterações no original\n",
    "for col in train_dataset.columns:\n",
    "    if train_dataset[col].dtype == 'object':  # Verifica se a coluna é categórica\n",
    "        train_dataset_encoded[col] = label_encoder.fit_transform(train_dataset[col])\n",
    "\n",
    "# Verificando a covariância entre as features e o label (redução de dimensionalidade)\n",
    "# grafico = FeatureCorrelation(labels=train_dataset_encoded.columns[1:17])\n",
    "# grafico.fit(train_dataset_encoded.iloc[:,1:17].values, train_dataset_encoded.iloc[:,17].values)\n",
    "# grafico.show();\n",
    "# train_dataset_preprocessed = train_dataset_encoded[['CALC','CH2O','CAEC','family_history_with_overweight','Weight','Age','NObeyesdad']]\n",
    "\n",
    "# Separação entre features e labels\n",
    "features = train_dataset_encoded.iloc[:,1:17].values # features removendo o id\n",
    "labels = train_dataset_encoded.iloc[:,17].values # labels\n",
    "# features = train_dataset_preprocessed.iloc[:,1:6].values # features removendo o id\n",
    "# labels = train_dataset_preprocessed.iloc[:,6].values # labels\n",
    "\n",
    "# Escalonando os dados (transformação de dados)\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha da técnica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_naive_bayes = []\n",
    "resultados_logistica = []\n",
    "resultados_forest = []\n",
    "\n",
    "for i in range(30):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, stratify = labels, random_state=i)\n",
    "    \n",
    "    naive_bayes = GaussianNB() # criação do modelo Naive Bayes\n",
    "    naive_bayes.fit(x_train,y_train) # treinamento do modelo Naive Bayes\n",
    "    resultados_naive_bayes.append(accuracy_score(y_test, naive_bayes.predict(x_test))) # avaliação do modelo Naive Bayes\n",
    "    \n",
    "    logistica = LogisticRegression(max_iter=1000) # criação do modelo de Regressão Logística\n",
    "    logistica.fit(x_train,y_train) # treinamento do modelo de Regressão Logística\n",
    "    resultados_logistica.append(accuracy_score(y_test, logistica.predict(x_test))) # avaliação do modelo de Regressão Logística\n",
    "\n",
    "    random_forest = RandomForestClassifier() # criação do modelo de Random Forest\n",
    "    random_forest.fit(x_train,y_train) # treinamento do modelo de Random Forest\n",
    "    resultados_forest.append(accuracy_score(y_test, random_forest.predict(x_test))) # avaliação do modelo de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes com média 0.6625561978163135 e desvio padrão 0.005871924080901997\n",
      "Regressão Logística com média 0.8582931920359668 e desvio padrão 0.0038558134761785923\n",
      "Random Forest com média 0.8998554913294796 e desvio padrão 0.0038432142632271347\n"
     ]
    }
   ],
   "source": [
    "medias = [np.mean(resultados_naive_bayes), np.mean(resultados_logistica),np.mean(resultados_forest)]\n",
    "std = [np.std(resultados_naive_bayes), np.std(resultados_logistica),np.std(resultados_forest)]\n",
    "print(f\"Naive Bayes com média {medias[0]} e desvio padrão {std[0]}\")\n",
    "print(f\"Regressão Logística com média {medias[1]} e desvio padrão {std[1]}\")\n",
    "print(f\"Random Forest com média {medias[2]} e desvio padrão {std[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização dos hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
