{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Prediction of Obesity Risk\n",
    "\n",
    "**Programa de Engenharia de Sistemas e Computação**\n",
    "\n",
    "**CPS833 - Data Mining**\n",
    "\n",
    "**Professor**: Geraldo Zimbrão da Silva\n",
    "\n",
    "**Aluno**: Luiz Henrique Souza Caldas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.target import FeatureCorrelation\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos dados\n",
    "train_dataset = pd.read_csv('train.csv')\n",
    "test_dataset = pd.read_csv('test.csv')\n",
    "\n",
    "# Verificação de dados ausentes (limpeza de dados)\n",
    "print(f\"{train_dataset.isnull().any().sum()} dados faltantes no dataset de treino\")\n",
    "print(f\"{train_dataset.isnull().any().sum()} dados faltantes no dataset de teste\")\n",
    "\n",
    "# Verificação de linhas duplicadas (redução de dimensionalidade)\n",
    "print(f\"{train_dataset.duplicated().sum()} linhas duplicadas no dataset de treino\")\n",
    "print(f\"{train_dataset.duplicated().sum()} linhas duplicadas no dataset de teste\")\n",
    "\n",
    "# TODO Verificação de ouliers (redução de dimensionalidade)\n",
    "\n",
    "# Codificando features categóricas com Label Encoder (transformação de dados)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_dataset_encoded = train_dataset.copy()  # Faz uma cópia do dataset de treino para evitar alterações no original\n",
    "for col in train_dataset.columns:\n",
    "    if train_dataset[col].dtype == 'object':  # Verifica se a coluna é categórica\n",
    "        train_dataset_encoded[col] = label_encoder.fit_transform(train_dataset[col])\n",
    "\n",
    "test_dataset_encoded = test_dataset.copy() # Faz uma cópia do dataset de teste para evitar alterações no original\n",
    "for col in test_dataset.columns:\n",
    "    if test_dataset[col].dtype == 'object':  # Verifica se a coluna é categórica\n",
    "        test_dataset_encoded[col] = label_encoder.fit_transform(test_dataset[col])\n",
    "\n",
    "# Separação entre features e labels no dataset de treinamento e remoção da coluna id nos dois datasets\n",
    "features = train_dataset_encoded.iloc[:,1:17].values # features do dataset de treino removendo o id\n",
    "labels = train_dataset_encoded.iloc[:,17].values # labels\n",
    "test = test_dataset_encoded.drop(columns=['id']) # removendo o id do dataset de teste\n",
    "\n",
    "# Escalonando os dados (transformação de dados)\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "test = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Modelo\n",
    "### Escolha da técnica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_naive_bayes = []\n",
    "resultados_logistica = []\n",
    "resultados_forest = []\n",
    "resultados_knn = []\n",
    "resultados_svm = []\n",
    "\n",
    "for i in range(30):\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    \n",
    "    naive_bayes = GaussianNB() # criação do modelo Naive Bayes\n",
    "    scores = cross_val_score(naive_bayes, features, labels, cv=kfold) # validação cruzada do modelo Naive Bayes\n",
    "    resultados_naive_bayes.append(scores.mean()) # avaliação do modelo Naive Bayes\n",
    "    \n",
    "    logistica = LogisticRegression(max_iter=300) # criação do modelo de Regressão Logística\n",
    "    scores = cross_val_score(logistica, features, labels, cv=kfold) # treinamento do modelo de Regressão Logística\n",
    "    resultados_logistica.append(scores.mean()) # avaliação do modelo de Regressão Logística\n",
    "\n",
    "    random_forest = RandomForestClassifier(n_jobs=-1, random_state=i) # criação do modelo de Random Forest\n",
    "    scores = cross_val_score(random_forest, features, labels, cv=kfold) # treinamento do modelo de Random Forest\n",
    "    resultados_forest.append(scores.mean()) # avaliação do modelo de Random Forest\n",
    "\n",
    "    knn = KNeighborsClassifier() # criação do modelo de k-NN \n",
    "    scores = cross_val_score(knn, features, labels, cv=kfold) # treinamento do modelo de k-NN \n",
    "    resultados_knn.append(scores.mean()) # avaliação do modelo de k-NN \n",
    "\n",
    "    svm = SVC() # criação do modelo de SVM\n",
    "    scores = cross_val_score(svm, features, labels, cv=kfold) # treinamento do modelo de SVM\n",
    "    resultados_svm.append(scores.mean()) # avaliação do modelo de SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO rede neural com tensor flow e GPU\n",
    "resultados_rede_neural = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Naïve Bayes com média {np.mean(resultados_naive_bayes)} e desvio padrão {np.std(resultados_naive_bayes)}\")\n",
    "print(f\"Regressão Logística com média {np.mean(resultados_logistica)} e desvio padrão {np.std(resultados_logistica)}\")\n",
    "print(f\"Random Forest com média {np.mean(resultados_forest)} e desvio padrão {np.std(resultados_forest)}\")\n",
    "print(f\"k-NN com média {np.mean(resultados_knn)} e desvio padrão {np.std(resultados_knn)}\")\n",
    "print(f\"SVM com média {np.mean(resultados_svm)} e desvio padrão {np.std(resultados_svm)}\")\n",
    "print(f\"Rede Neural com média {np.mean(resultados_rede_neural)} e desvio padrão {np.std(resultados_rede_neural)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A técnica Random Forest obteve a maior média, então mesmo com seu desvio padrão sendo o maior, foi a técnica selecionada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização dos hiperparâmetros com validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, stratify = labels)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, 40, None],\n",
    "    'max_features': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3, 5],\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, \n",
    "                          cv = 10, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Melhores parâmetros {grid_search.best_params_}\")\n",
    "print(f\"Melhor score {grid_search.best_score_} no conjunto de treinamento\")\n",
    "\n",
    "random_forest = grid_search.best_estimator_\n",
    "y_predict = random_forest.predict(x_test)\n",
    "resultado = accuracy_score(y_test, y_predict)\n",
    "print(f\" Score no conjunto de teste {resultado}\")\n",
    "\n",
    "print(f\"O ganho após a otimização foi de {(np.mean(resultados_forest)-resultado)*100:.4f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do modelo usando o dataset de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, stratify = labels)\n",
    "    \n",
    "naive_bayes = GaussianNB() # criação do modelo Naive Bayes\n",
    "naive_bayes.fit(x_train,y_train) # treinamento do modelo Naive Bayes\n",
    "y_predict_naive_bayes = naive_bayes.predict(x_test) # classificação com o modelo Naive Bayes\n",
    "resultado_naive_bayes = accuracy_score(y_test, y_predict_naive_bayes) # percentual de acerto do modelo Naive Beyes\n",
    "\n",
    "random_forest = RandomForestClassifier(max_depth=2000, max_features=5, min_samples_leaf=2, n_estimators=700, n_jobs=-1) # criação do modelo de Random Forest\n",
    "random_forest.fit(x_train,y_train) # treinamento do modelo de Random Forest\n",
    "y_predict_forest = random_forest.predict(x_test) # classificação com o modelo Random Forest\n",
    "resultado_forest = accuracy_score(y_test, y_predict_forest) # percentual de acerto do modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação dos resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodificando os labels\n",
    "mapeamento = {\n",
    "    0: \"Insufficient_Weight\",\n",
    "    1: \"Normal_Weight\",\n",
    "    2: \"Obesity_Type_I\",\n",
    "    3: \"Obesity_Type_II\",\n",
    "    4: \"Obesity_Type_III\",\n",
    "    5: \"Overweight_Level_I\",\n",
    "    6: \"Overweight_Level_II\"\n",
    "}\n",
    "y_predict_naive_bayes = [mapeamento[i] for i in y_predict_naive_bayes]\n",
    "y_predict_forest = [mapeamento[i] for i in y_predict_forest]\n",
    "y_test = [mapeamento[i] for i in y_test]\n",
    "\n",
    "cm_nb = confusion_matrix(y_test, y_predict_naive_bayes)\n",
    "cm_rf = confusion_matrix(y_test, y_predict_forest)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.heatmap(cm_nb, annot=True, cmap='Blues', fmt='d', ax=axs[0])\n",
    "axs[0].set_title('Matriz de Confusão para o modelo Naïve Beyes')\n",
    "axs[0].set_xlabel('Predicted labels')\n",
    "axs[0].set_ylabel('True labels')\n",
    "sns.heatmap(cm_rf, annot=True, cmap='Blues', fmt='d', ax=axs[1])\n",
    "axs[1].set_title('Matriz de Confusão para o modelo Random Forest')\n",
    "axs[1].set_xlabel('Predicted labels')\n",
    "axs[1].set_ylabel('True labels')\n",
    "\n",
    "print(f\"A acurácia do Naïve Beyes foi de {resultado_naive_bayes}\")\n",
    "print(f\"A acurácia do Random Forest foi de {resultado_forest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação do dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(max_depth=2000, max_features=5, min_samples_leaf=2, n_estimators=700, n_jobs=-1) # criação do modelo de Random Forest\n",
    "random_forest.fit(features,labels) # treinamento do modelo de Random Forest com o dataset de treinamento completo\n",
    "y_predict_forest = random_forest.predict(test) # classificação com o modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acesse os estimadores (árvores) individuais\n",
    "estimadores = random_forest\n",
    "\n",
    "# Examine a profundidadede cada árvore\n",
    "profundidade_arvores = [estimador.tree_.max_depth for estimador in estimadores]\n",
    "\n",
    "# Calculando o tamanho médio e máximo das árvores\n",
    "profundidade_media = sum(profundidade_arvores) / len(profundidade_arvores)\n",
    "profundidade_maxima = max(profundidade_arvores)\n",
    "\n",
    "print(\"Profundidade Média das Árvores:\", profundidade_media)\n",
    "print(\"Profundidade Máxima das Árvores:\", profundidade_maxima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapeamento = {\n",
    "    0: \"Insufficient_Weight\",\n",
    "    1: \"Normal_Weight\",\n",
    "    2: \"Obesity_Type_I\",\n",
    "    3: \"Obesity_Type_II\",\n",
    "    4: \"Obesity_Type_III\",\n",
    "    5: \"Overweight_Level_I\",\n",
    "    6: \"Overweight_Level_II\"\n",
    "}\n",
    "predict_categorico = [mapeamento[i] for i in y_predict_forest]\n",
    "resultado = np.column_stack((test_dataset['id'].values, predict_categorico))\n",
    "np.savetxt('resuldado.csv', resultado, delimiter=',', header=\"id,NObeyesdad\", fmt='%s', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
